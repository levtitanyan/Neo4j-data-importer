{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.graph_transformers.llm import LLMGraphTransformer\n",
    "from langchain.schema import Document\n",
    "from neo4j import GraphDatabase\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# functions\n",
    "def split_text(text, chunk_size=4000):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "async def process_text_in_batches(text, chapter_name, batch_size=10):\n",
    "    chunks = split_text(text)\n",
    "    documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "    batched_documents = [documents[i:i + batch_size] for i in range(0, len(documents), batch_size)]\n",
    "    all_graph_documents = []\n",
    "\n",
    "    for batch in batched_documents:\n",
    "            ## here must be prompt\n",
    "        batch_graph_documents = await llm_transformer.aconvert_to_graph_documents(batch)\n",
    "        print(batch_graph_documents[0].nodes)\n",
    "        \n",
    "        for doc in batch_graph_documents:\n",
    "            for node in doc.nodes:\n",
    "                node.properties['chapter'] = chapter_name\n",
    "        \n",
    "        all_graph_documents.extend(batch_graph_documents)\n",
    "    \n",
    "    return all_graph_documents\n",
    "\n",
    "\n",
    "def read_text_from_pdf(file_path, pages):\n",
    "    pdf_document = fitz.open(file_path)\n",
    "    all_text = \"\"\n",
    "    for start, end in pages:\n",
    "        print(f\"Extracting text from pages {start} to {end}\")\n",
    "        for page_num in range(start - 1, end):\n",
    "            try:\n",
    "                page = pdf_document.load_page(page_num)\n",
    "                text = page.get_text(\"text\")\n",
    "                all_text += text + \"\\n\"\n",
    "            except ValueError as e:\n",
    "                print(f\"Error loading page {page_num + 1}: {e}\")\n",
    "    pdf_document.close()\n",
    "    return all_text\n",
    "\n",
    "async def main():\n",
    "    pdf_path = r\"/Users/titanyanlev/Desktop/future intelligence .pdf\"\n",
    "\n",
    "    all_graph_documents_nodes = []\n",
    "    all_graph_documents_relationships = []\n",
    "\n",
    "    for chapter_name, pages in zip(chapter_names, pages_to_extract):\n",
    "        print(f\"Processing chapter: {chapter_name} with pages: {pages}\")\n",
    "        text = read_text_from_pdf(pdf_path, [pages])\n",
    "\n",
    "        graph_documents = await process_text_in_batches(text, chapter_name)\n",
    "\n",
    "        graph_documents_nodes = graph_documents[0].nodes \n",
    "        graph_documents_relationships = graph_documents[0].relationships\n",
    "\n",
    "\n",
    "        all_graph_documents_nodes.extend(graph_documents_nodes)\n",
    "        all_graph_documents_relationships.extend(graph_documents_relationships)\n",
    "        \n",
    "    return all_graph_documents_nodes,all_graph_documents_relationships\n",
    "\n",
    "def create_node(tx, node):\n",
    "    query = f\"\"\"\n",
    "    MERGE (n:{node['type']} {{id: $id, name: $id, chapter: $chapter}})\n",
    "    RETURN n\n",
    "    \"\"\"\n",
    "    tx.run(query, id=node[\"id\"], chapter=node['chapter'])\n",
    "\n",
    "def create_relationship(tx, edge):\n",
    "    # Ensure the relationship type is properly formatted as a string\n",
    "    relationship_type = edge['type']\n",
    "    query = f\"\"\"\n",
    "    MATCH (a {{id: $source_id}})\n",
    "    MATCH (b {{id: $target_id}})\n",
    "    MERGE (a)-[r:`{relationship_type}` {{chapter: $chapter}}]->(b)\n",
    "    RETURN r\n",
    "    \"\"\"\n",
    "    tx.run(query, source_id=edge[\"source\"], target_id=edge[\"target\"], chapter=edge.get('chapter', 'Unknown'))\n",
    "\n",
    "# Prompt\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You're working on an advanced project to transform PDF text into unique nodes and relationships for a Neo4j database.\"),\n",
    "    (\"system\", \"This project requires creating over 1000 unique nodes and 1000 unique relationships, ensuring high accuracy and efficiency.\"),\n",
    "    (\"system\",\"make such nodes and relationships so that when using the graph information, one can get all the information the was provided in the source\"),\n",
    "    (\"system\",\"include more properties, not only id and name, e.g. year etc.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "node_properties = [\"type\", \"name\", \"chapter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"your-api-key\"\n",
    "your_llm_instance = ChatOpenAI(temperature=0.7,api_key=os.environ['OPENAI_API_KEY'], model_name=\"gpt-4-turbo\")\n",
    "llm_transformer = LLMGraphTransformer(llm=your_llm_instance,prompt=template,node_properties=node_properties)\n",
    "\n",
    "## custom names and pages\n",
    "chapter_names = [\"Future of Healthcare\", \"Future of Consumption\", \"Future of Food\", \"Future of Entertainment\"]\n",
    "pages_to_extract = [(60, 72), (139,147), (148, 160), (236, 242)]  # Adjust page ranges as needed\n",
    "\n",
    "# custom account\n",
    "url = \"neo4j+s://a1e9ad6b.databases.neo4j.io\"\n",
    "username = \"neo4j\"\n",
    "password = \"your_password\"\n",
    "enviromental_variable = \"NEO4J_URL\"\n",
    "\n",
    "driver = GraphDatabase.driver(url, auth=(username, password))\n",
    "nest_asyncio.apply()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
